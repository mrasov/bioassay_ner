{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T17:01:53.989576Z",
     "iopub.status.busy": "2025-02-02T17:01:53.989278Z",
     "iopub.status.idle": "2025-02-02T17:02:14.344633Z",
     "shell.execute_reply": "2025-02-02T17:02:14.343976Z",
     "shell.execute_reply.started": "2025-02-02T17:01:53.989542Z"
    },
    "id": "HfgU_LLJSKoo",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer, DataCollatorForTokenClassification, get_scheduler\n",
    "import evaluate\n",
    "from accelerate import Accelerator\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T17:02:14.346693Z",
     "iopub.status.busy": "2025-02-02T17:02:14.346098Z",
     "iopub.status.idle": "2025-02-02T17:02:14.649502Z",
     "shell.execute_reply": "2025-02-02T17:02:14.648684Z",
     "shell.execute_reply.started": "2025-02-02T17:02:14.346670Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 7000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 577\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('/kaggle/input/ner_data_raw.prqt')\n",
    "df = df.sample(frac=1, random_state=111).reset_index(drop=True)\n",
    "\n",
    "label2id = {\n",
    "    'O': 0,\n",
    "    'B-TARGET': 1, \n",
    "    'I-TARGET': 2,\n",
    "    'B-SUBSTRATE': 3,\n",
    "    'I-SUBSTRATE': 4\n",
    "}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "label_names = list(label2id.keys())\n",
    "\n",
    "df['tokens'] = df.ner_data.apply(lambda x: [_[0] for _ in x])\n",
    "df['ner_tags'] = df.ner_data.apply(lambda x: [label2id[_[1]] for _ in x])\n",
    "\n",
    "raw_datasets = DatasetDict(\n",
    "    {\n",
    "    'train': Dataset.from_pandas(df[['tokens', 'ner_tags']].iloc[:7000, :]),\n",
    "    'validation': Dataset.from_pandas(df[['tokens', 'ner_tags']].iloc[7000:7500, :]),\n",
    "    'test': Dataset.from_pandas(df[['tokens', 'ner_tags']].iloc[7500:, :])\n",
    "    }\n",
    ")\n",
    "\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T17:02:14.650971Z",
     "iopub.status.busy": "2025-02-02T17:02:14.650671Z",
     "iopub.status.idle": "2025-02-02T17:02:19.763771Z",
     "shell.execute_reply": "2025-02-02T17:02:19.762580Z",
     "shell.execute_reply.started": "2025-02-02T17:02:14.650906Z"
    },
    "id": "kiB2ZEeRSKou",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c9cd53bc8474e6d87aaf16198129a0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/379 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234c540339f049dfa639cdc9ea293c0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/225k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f94a90e3d6043c6828bdd593c9e9515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/447k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46bc387a210a4125bc31be5dc91031fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525bcc49cb8f4ac4ba476b1347692148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/559 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d3e9906121e4cc8b404ff58c6bceb3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at michiyasunaga/BioLinkBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28895, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_checkpoint = \"michiyasunaga/BioLinkBERT-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T17:02:19.766042Z",
     "iopub.status.busy": "2025-02-02T17:02:19.765483Z",
     "iopub.status.idle": "2025-02-02T17:02:19.776525Z",
     "shell.execute_reply": "2025-02-02T17:02:19.775834Z",
     "shell.execute_reply.started": "2025-02-02T17:02:19.766008Z"
    },
    "id": "buFJQiBlSKov",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            label = labels[word_id]\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }\n",
    "\n",
    "def postprocess(predictions, labels):\n",
    "    predictions = predictions.detach().cpu().clone().numpy()\n",
    "    labels = labels.detach().cpu().clone().numpy()\n",
    "\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    return true_labels, true_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T17:02:19.777689Z",
     "iopub.status.busy": "2025-02-02T17:02:19.777330Z",
     "iopub.status.idle": "2025-02-02T17:02:21.656810Z",
     "shell.execute_reply": "2025-02-02T17:02:21.656142Z",
     "shell.execute_reply.started": "2025-02-02T17:02:19.777661Z"
    },
    "id": "580w11ewSKow",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9d1a47c18c3449197187cf80d5caa0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dac2e6c0f1c4e9495db2fca220ea1a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd9f9879e32470aab58113bba4bd3d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/577 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f441e929f846f2ad8ca349187f2497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"train\"].column_names,\n",
    ")\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "metric = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T17:02:21.657886Z",
     "iopub.status.busy": "2025-02-02T17:02:21.657675Z",
     "iopub.status.idle": "2025-02-02T17:02:21.838780Z",
     "shell.execute_reply": "2025-02-02T17:02:21.837802Z",
     "shell.execute_reply.started": "2025-02-02T17:02:21.657866Z"
    },
    "id": "QjYGL1QhSKo2",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=64,\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"validation\"], collate_fn=data_collator, batch_size=64\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"test\"], collate_fn=data_collator, batch_size=64\n",
    ")\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "accelerator = Accelerator()\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")\n",
    "\n",
    "num_train_epochs = 5\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "\n",
    "! mkdir linkbert_bioassay_ner\n",
    "output_dir = \"linkbert_bioassay_ner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T17:02:21.841942Z",
     "iopub.status.busy": "2025-02-02T17:02:21.841709Z",
     "iopub.status.idle": "2025-02-02T17:08:29.682166Z",
     "shell.execute_reply": "2025-02-02T17:08:29.681216Z",
     "shell.execute_reply.started": "2025-02-02T17:02:21.841921Z"
    },
    "id": "UyV7y2e3SKo3",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19bc9ebdc234c35b9d86eb1fba02e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'precision': 0.9138166894664843, 'recall': 0.835, 'f1': 0.8726322664924886, 'accuracy': 0.9782276268841477}\n",
      "epoch 1: {'precision': 0.9233926128590971, 'recall': 0.8522727272727273, 'f1': 0.8864084044648719, 'accuracy': 0.9778635403771936}\n",
      "epoch 2: {'precision': 0.9247606019151847, 'recall': 0.8813559322033898, 'f1': 0.9025367156208278, 'accuracy': 0.9820141265564698}\n",
      "epoch 3: {'precision': 0.9220246238030095, 'recall': 0.8730569948186528, 'f1': 0.8968729208250165, 'accuracy': 0.9812859535425618}\n",
      "epoch 4: {'precision': 0.9247606019151847, 'recall': 0.8745148771021992, 'f1': 0.898936170212766, 'accuracy': 0.9816500400495157}\n"
     ]
    }
   ],
   "source": [
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    model.eval()\n",
    "    for batch in eval_dataloader:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        labels = batch[\"labels\"]\n",
    "\n",
    "        predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n",
    "        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n",
    "\n",
    "        predictions_gathered = accelerator.gather(predictions)\n",
    "        labels_gathered = accelerator.gather(labels)\n",
    "\n",
    "        true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)\n",
    "        metric.add_batch(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "    results = metric.compute()\n",
    "    print(\n",
    "        f\"epoch {epoch}:\",\n",
    "        {\n",
    "            key: results[f\"overall_{key}\"]\n",
    "            for key in [\"precision\", \"recall\", \"f1\", \"accuracy\"]\n",
    "        },\n",
    "    )\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "    if accelerator.is_main_process:\n",
    "        tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "accelerator.wait_for_everyone()\n",
    "unwrapped_model = accelerator.unwrap_model(model)\n",
    "unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T17:08:29.683576Z",
     "iopub.status.busy": "2025-02-02T17:08:29.683351Z",
     "iopub.status.idle": "2025-02-02T17:08:31.975572Z",
     "shell.execute_reply": "2025-02-02T17:08:31.974695Z",
     "shell.execute_reply.started": "2025-02-02T17:08:29.683557Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final metric on test set: {'precision': 0.9422632794457275, 'recall': 0.8898582333696837, 'f1': 0.9153112731351654, 'accuracy': 0.9840529648819805}\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for batch in test_dataloader:\n",
    "    batch.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    predictions = outputs.logits.argmax(dim=-1)\n",
    "    labels = batch[\"labels\"]\n",
    "\n",
    "    predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n",
    "    labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n",
    "\n",
    "    predictions_gathered = accelerator.gather(predictions)\n",
    "    labels_gathered = accelerator.gather(labels)\n",
    "\n",
    "    true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)\n",
    "    metric.add_batch(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "results = metric.compute()\n",
    "print(\n",
    "    f\"Final metric on test set:\",\n",
    "    {\n",
    "        key: results[f\"overall_{key}\"]\n",
    "        for key in [\"precision\", \"recall\", \"f1\", \"accuracy\"]\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T17:08:31.976800Z",
     "iopub.status.busy": "2025-02-02T17:08:31.976494Z",
     "iopub.status.idle": "2025-02-02T17:08:31.994335Z",
     "shell.execute_reply": "2025-02-02T17:08:31.993726Z",
     "shell.execute_reply.started": "2025-02-02T17:08:31.976769Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]         O\n",
      "activation    O\n",
      "of            O\n",
      "human         O\n",
      "beta          B-TARGET\n",
      "-             I-TARGET\n",
      "adrenergic    I-TARGET\n",
      "receptor      I-TARGET\n",
      "by            O\n",
      "isoproterenol B-SUBSTRATE\n",
      "at            O\n",
      "0             O\n",
      ".             O\n",
      "5             O\n",
      "um            O\n",
      "measured      O\n",
      "as            O\n",
      "increase      O\n",
      "in            O\n",
      "camp          O\n",
      "levels        O\n",
      "[SEP]         O\n"
     ]
    }
   ],
   "source": [
    "text = 'Activation of human beta-adrenergic receptor by isoproterenol at 0.5 uM measured as increase in cAMP levels'\n",
    "\n",
    "example = tokenizer(text, return_tensors=\"pt\").to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**example).logits\n",
    "\n",
    "predictions = torch.argmax(logits, dim=2)\n",
    "predicted_token_class = [model.config.id2label[t.item()] for t in predictions[0]]\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(example['input_ids'][0])\n",
    "max_length = max(len(token) for token in tokens)\n",
    "\n",
    "for token, label in zip(tokens, predicted_token_class):\n",
    "    print(f\"{token: <{max_length}} {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T17:08:31.995136Z",
     "iopub.status.busy": "2025-02-02T17:08:31.994958Z",
     "iopub.status.idle": "2025-02-02T17:08:52.985555Z",
     "shell.execute_reply": "2025-02-02T17:08:52.984736Z",
     "shell.execute_reply.started": "2025-02-02T17:08:31.995120Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/linkbert_bioassay_ner.zip'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_directory = 'linkbert_bioassay_ner'\n",
    "archive_path = 'linkbert_bioassay_ner.zip'\n",
    "shutil.make_archive(archive_path.replace('.zip', ''), 'zip', source_directory)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Token classification (PyTorch)",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6588740,
     "sourceId": 10641480,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
